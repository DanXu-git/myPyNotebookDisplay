std_prj_person = rename(std_prj_person, s_num='(!filter_only)')
std_prj_person = rename(std_prj_person, s_num=\(!filter_only\))
std_prj_person = rename(std_prj_person, s_num=\(\!filter_only\))
std_prj_person$`(!filter_only)`
std_prj_person = rename(std_prj_person, count=(!filter_only) )
std_prj_person$standard_project = std_prj_person$`(!filter_only)`
std_prj_person = subset(std_prj_person, select = -(!filter_only))
std_prj_person = subset(std_prj_person, select = -'(!filter_only)')
std_prj_person = subset(std_prj_person, select = -"(!filter_only)")
std_prj_person = subset(std_prj_person, select = -c("(!filter_only)"))
dump(ls(), file = "Work/PRJdata_full.RData")
plot_ly(y = standard_project, color = apply_man, data = std_prj_person, type="box")
plot_ly(y = standard_project, color = apply_man, data = std_prj_person, type="box"))
plot_ly(y = standard_project, color = apply_man, data = std_prj_person, type="box")
std_prj_person$standard_project
plot_ly(y = standard_project, color = apply_man, data = std_prj_person, type="box")
with(std_prj_person, plot_ly(y = standard_project, color = apply_man, type="box"))
with(std_prj_person, plot_ly(x = f_date, y = standard_project, color = apply_man))
with(std_prj_person, plot_ly(x = f_date, y = standard_project, color = apply_man, type = "line"))
with(std_prj_person, plot_ly(x = f_date, y = standard_project, color = apply_man, type = "pie"))
with(std_prj_person, plot_ly(x = f_date, y = standard_project, color = apply_man, type = "surface"))
with(std_prj_person, plot_ly(x = f_date, y = standard_project, color = apply_man, type = "scatter3d"))
with(std_prj_person, plot_ly(x = f_date, y = standard_project, color = apply_man, type = "scatter"))
with(std_prj_person, plot_ly(x = f_date, y = standard_project, color = apply_man, type = "histogram2d"))
with(std_prj_person, plot_ly(x = f_date, y = standard_project, color = apply_man, type = "pie"))
warning()
plot_ly(std_prj_person, x = f_date, y = standard_project, mode = "markers")
names(std_prj_person)
with(std_prj_person, plot_ly(x = f_date, y = standard_project, mode = "markers"))
plot_ly(std_prj_person, standard_project ~ f_date)
with(std_prj_person, plot_ly(std_prj_person, standard_project ~ f_date))
with(std_prj_person, plot_ly(standard_project ~ f_date))
class(std_prj_person)
data("airmiles")
plot_ly( x=time(airmiles), y=airmiles)
head(airmiles)
time(airmiles)
airmiles
plot_ly( x=std_prj_person$standard_project, y=std_prj_person$f_date)
plot_ly( y=std_prj_person$standard_project, x=std_prj_person$f_date, color=std_prj_person$apply_man)
add_lines(plot_ly( y=std_prj_person$standard_project, x=std_prj_person$f_date, color=std_prj_person$apply_man))
std_prj_person
View(para_num)
View(nrt)
add_lines(plot_ly( y=std_prj_person$standard_project, x=std_prj_person$f_date, color=std_prj_person$apply_man))
suppressWarnings(add_lines(plot_ly( y=std_prj_person$standard_project, x=std_prj_person$f_date, color=std_prj_person$apply_man)))
suppressMessages(add_lines(plot_ly( y=std_prj_person$standard_project, x=std_prj_person$f_date, color=std_prj_person$apply_man)))
dim(std_prj_person)
add_lines(plot_ly( y=all_pgj_person$standard_project, x=all_pgj_person$f_date, color=all_pgj_person$apply_man))
add_lines(plot_ly(y=all_pgj_person$standard_project, x=all_pgj_person$f_date, color=all_pgj_person$apply_man))
add_lines(plot_ly(y=all_pgj_person$s_num, x=all_pgj_person$f_date, color=all_pgj_person$apply_man))
View(nrt)
add_lines(plot_ly( y=std_prj_person$standard_project, x=std_prj_person$f_date, color=std_prj_person$apply_man))
q()
q()
q()
log2(1.5)
log2(2)
log2(1.5)
log(1.5, base=2)
q()
install.packages(ffbase)
install.packages("ffbase")
require(ffbase)
niftyAll = read.table.ffdf("/Volumes/Seagate BUP Slim OS/Data/Health/BI_MDM_NIFTY_SAMPLE.csv", FUN = "red.csv", na.strings="", header=T)
sample_month = seq(36, 3000, 8000)
sample_month
seq(0,1, 10)
?seq
seq(1000, 8000, length.out = 36)
sample_month = seq(1000, 8000, length.out = 36) + round(rnorm(36, 500, 300))
sample_month
plot(sample_month, type="l")
sample_month = ts(sample_month, frequency = 12, start = 2014)
sample_month
library(forecast)
tsTrain = window(sample_month, start = 2014, end = 2016 + 6/12)
tsTest = window(sample_month, start = 2016 + 6/12)
est1 = ets(tsTrain)
fcast = forecast(est1)
plot(fcast); lines(ts1Test, col="red")
plot(fcast)
plot(fcast)
lines(tsTest, col="red")
?ets
acf(tsTrain)
acf(diff(tsTrain, lag = 1))
acf(diff(tsTrain, lag = 7))
acf(diff(tsTrain, lag = 1))
acf(diff(tsTrain, lag = 12))
accuracy(fcast, tsTest)
fit <- auto.arima(tsTrain)
fcast = forecast(fit, h=12)
accuracy(fcast, tsTrain)
plot(fcast)
lines(tsTest, col="red")
accuracy(fcast, tsTrain)
tsTest = window(sample_month, start = 2016 + 6/12, end = 2017 - 0.01)
times(sample_month)
time(sample_month)
sample_month
tsTest = window(sample_month, start = 2016 + 6/12, end = 2017)
tsTest = window(sample_month, start = 2016 + 6/12)
tsTest
tsTest = window(sample_month, start = 2016 + 6/12, end = 2016+12/12)
tsTest = window(sample_month, start = 2016 + 6/12, end = 2016+12/12- 0.1)
tsTest
tsTest = window(sample_month, start = 2016 + 6/12)
accuracy(fcast, tsTrain)
tsTrain
tsTest = window(sample_month, start = 2016 + 7/12)
accuracy(fcast, tsTrain)
tsTest = window(sample_month, start = 2016 + 6/12)
accuracy(fcast, tsTest)
est1 = ets(tsTrain, model = "MMM")
ets_fcast = forecast(est1, h=12)
plot(ets_fcast)
lines(tsTest, col="red")
est1 = ets(tsTrain, model = "MMM")
ets_fcast = forecast(est1)
plot(ets_fcast)
lines(tsTest, col="red")
est1 = ets(tsTrain, model = "ZAA")
ets_fcast = forecast(est1)
plot(ets_fcast)
lines(tsTest, col="red")
accuracy(ets_fcast, tsTest)
plot(ets_fcast, main = "Sample Numbers Trend", ylab = "sample Number per Month")
lines(tsTest, col="red")
accuracy(fcast, tsTest)
plot(fcast)
lines(tsTest, col="red")
fcast
class(fcast)
dput(sample_month, "Work/全样品系统/sample_month.Rda")
rm(list=ls())
dget
dget("Work/全样品系统/sample_month.Rda")
q()
log2(1.5)
q()
x = c(0.00000123, 0.0000000097, 0.000045)
scale(x)
q()
knitr::opts_chunk$set(echo = FALSE)
suppressMessages(library(caret))
suppressPackageStartupMessages(library(ggplot2))
df1 <- read.csv("pml-training.csv", header=T)
validation <- read.csv("pml-testing.csv", header=T) #validation set
##create a new df of useful predictors.
set.seed(32323)
NZV <- nearZeroVar(df1)
df1 <- df1[, -NZV]
AllNA <- sapply(df1, function(x) mean(is.na(x))) > 0.95
df1 <- df1[, AllNA==FALSE]
#$create training and testing data sets
inTrain <- createDataPartition(df1$classe, p=.75, list=FALSE)
training <- df1[inTrain, ]
testing <- df1[-inTrain, ]
suppressWarnings(modFit_lda <- train(classe ~ . , method='rf', data=training))
pred <- predict(modFit_lda, testing)
conMatr <- confusionMatrix(testing$classe, pred)
acclda <- conMatr$overall[[1]]
tb1 <- conMatr$table; tb1 <- tb1/rowSums(tb1)
Df <- as.data.frame(tb1)
g <- ggplot( Df, aes(x=Reference, y=Prediction, fill=Freq))
g = g + geom_tile() + scale_fill_gradient(low="white", high="steelblue")
g + geom_text(aes(label=round(Freq,2)))
predict(modFit_lda, validation)
controlLDA <- trainControl(method='cv', number=3)
suppressWarnings(modFit_lda <- train(classe ~ . , method='lda', data=training, trainControl=controlLDA))
predict(modFit_lda, validation)
q()
library(caret)
q()
data(galton)
library(UsingR)
data(galton)
y <- galton$child - mean(galton$child)
x <- galton$parent - mean(galton$parent)
freqData <- as.data.frame(table(x, y))
names(freqData) <- c("child", "parent", "freq")
freqData$child <- as.numeric(as.character(freqData$child))
freqData$parent <- as.numeric(as.character(freqData$parent))
myPlot <- function(beta){
g <- ggplot(filter(freqData, freq > 0), aes(x = parent, y = child))
g <- g + scale_size(range = c(2, 20), guide = "none" )
g <- g + geom_point(colour="grey50", aes(size = freq+20, show_guide = FALSE))
g <- g + geom_point(aes(colour=freq, size = freq))
g <- g + scale_colour_gradient(low = "lightblue", high="white")
g <- g + geom_abline(intercept = 0, slope = beta, size = 3)
mse <- mean( (y - beta * x) ^2 )
g <- g + ggtitle(paste("beta = ", beta, "mse = ", round(mse, 3)))
g
}
manipulate(myPlot(beta), beta = slider(0.6, 1.2, step = 0.02))
library(manipulate)
library(manipulate)
install.packages("manipulate")
library(manipulate)
manipulate(myPlot(beta), beta = slider(0.6, 1.2, step = 0.02))
View(freqData)
manipulate(myPlot(beta), beta = slider(0.6, 1.2, step = 0.02))
x <- filter(freqData, freq > 0)
x <- filter(freqData, freqData$freq > 0)
head(x)
freqData$freq > 0
x
x <- filter(freqData, freq > 0)
library(dplyr)
x <- filter(freqData, freq > 0)
x
manipulate(myPlot(beta), beta = slider(0.6, 1.2, step = 0.02))
q()
ruinf(8, 3000)
runif(8, 3000)
runif(8)
runif(8,20000,50000)
x = round(runif(8,20000,50000))
t(x)
x
as.vector(x)
t(as.vector(x))
as.data.frame(x)
as.data.frame(x)$x
as.data.frame(x)[,1]
x = round(runif(8,2000,5000))
as.data.frame(x)[,1]
as.data.frame(x)
as.data.frame(x)/4
round(as.data.frame(x)/4)
q()
x = runif(100000)
y = runif(100000)
p = mean(x^2 + y^2 < 1)
p * 4
x = runif(200000)
y = runif(200000)
p = mean(x^2 + y^2 < 1)
p * 4
source("markov_caculate_pi.R")
markov_caculate_pi(1000000)
markov_caculate_pi(2000000)
markov_caculate_pi(2000000)
markov_caculate_pi(2000000)
markov_caculate_pi(3000000)
markov_caculate_pi(5000000)
markov_caculate_pi(5000000)
markov_caculate_pi(6000000)
markov_caculate_pi(6000000)
q()
round(runif(12, 3000))
round(runif(12, 3000, 6000))
data.frame(round(runif(12, 3000, 6000)))
q()
library(devtools)
devtools::install_github('jtleek/tidypvals')
q()
source("markov_caculate_pi.R")
markov_caculate_pi()
markov_caculate_pi
markov_caculate_pi(1000000)
q()
freqData$parent <- as.numeric(as.character(freqData$parent))
source('~/Data_Science/R_work_dir/Theorem_similization/regression_line_finding.R')
source('~/Data_Science/R_work_dir/Theorem_similization/regression_line_finding.R')
source('~/Data_Science/R_work_dir/Theorem_similization/regression_line_finding.R')
q()
library(rgl)
install.packages("rgl")
library(rgl)
q()
x <- runif(16, 20)
x <- runif(16)
x <- matrix(x, 4, 4)
x
y <- runif(4)
solve(x, y)
xy <- cbind(x, y)
solve(xy)
solve(x)
y
?solve
ix <- solve(x)
x %*% ix
ix %*% x
x * ix
ix * x
y
solve(y)
solve(x)
solve(x, y)
y %*% solve(x)
y
solve(x)
ix <- solve(x)
x %*% ix
ix %*% x
q()
q()
A=matrix(c(1,-2,1,1,
1,-2,1,-1,
2,4,2,5,
-3,2,6,3),nrow=4,ncol=4,byrow=T)
B=c(2,-3,4,1)
A
solve(A, B)
solve(t(A)) %*% B
solve(t(A)) %*% t(B)
solve(A) %*% B
B
iA = solve(A)
A %*% iA
iA %*% A
B %*% iA
iA %*% B
solve(A, B)
t(B) %*% iA
t(B)
B
q()
A = matrix(c(1,2,3,4), 2, 2, byrow = T)
A
A %*% t(A)
t(A)
T(A)
q()
q()
q()
df = read.csv("/Users/Stamn/Data_Science/Python_work_dir/input/August_DP.csv", header=TRUE)
df = read.csv("/Users/Stamn/Data_Science/Python_work_dir/input/August_DP.csv", header=TRUE, na.strings = "", stringsAsFactors = FALSE)
df = read.csv("/Users/Stamn/Data_Science/Python_work_dir/input/August_DP.csv", header=TRUE, na.strings = "", stringsAsFactors = FALSE)
df = read.csv("/Users/Stamn/Data_Science/Python_work_dir/input/August_DP2.csv", header=TRUE, na.strings = "", stringsAsFactors = FALSE)
head(df)
library(caret)
inTrain = createDataPartition(df$FLOWCELL, p=.8, list=FALSE)
inTrain = createDataPartition(df, p=.8, list=FALSE)
inTrain = createDataPartition(df$Type, p=.8, list=FALSE)
colnames(df)
modFit <- train("分析时间" ~ . , method = 'glm', data=df)
modFit <- train('分析时间' ~ . , method = 'glm', data=df)
df = read.csv("/Users/Stamn/Data_Science/Python_work_dir/input/August_DP2.csv", header=TRUE, na.strings = "", stringsAsFactors = FALSE)
colnames(df)
modFit <- train(Comsu_time ~ Yield + Type + Area , method = 'glm', data=df)
df = read.csv("/Users/Stamn/Data_Science/Python_work_dir/input/August_DP.csv", header=TRUE, na.strings = "", stringsAsFactors = FALSE)
df = read.csv("/Users/Stamn/Data_Science/Python_work_dir/input/August_DP.csv", header=TRUE, na.strings = "", stringsAsFactors = FALSE)
df = read.csv("/Users/Stamn/Data_Science/Python_work_dir/input/August_DP.csv", header=TRUE, na.strings = "", stringsAsFactors = FALSE)
df = read.csv("/Users/Stamn/Data_Science/Python_work_dir/input/August_DP.csv", header=TRUE, na.strings = "", stringsAsFactors = FALSE)
df = read.csv("/Users/Stamn/Data_Science/Python_work_dir/input/August_DP.csv", header=TRUE, na.strings = "", stringsAsFactors = FALSE)
df = read.csv("/Users/Stamn/Data_Science/Python_work_dir/input/August_DP.csv", header=TRUE, na.strings = "")
df = read.csv("/Users/Stamn/Data_Science/Python_work_dir/input/August_DP.csv", header=TRUE, na.strings = "")
df = read.csv("/Users/Stamn/Data_Science/Python_work_dir/input/August_DP2.csv", header=TRUE, na.strings = "")
modFit <- train(Comsu_time ~ Yield + Type + Area , method = 'glm', data=df)
warnings()
preds <- predict(modFit, newdata = df)
cbind(df$Comsu_time, preds)
mean((preds - df$Comsu_time)^2)
conMatr <- confusionMatrix(df$Comsu_time, pred)
conMatr <- confusionMatrix(df$Comsu_time, preds)
(preds - mean(preds))^2 / (df$Comsu_time - mean(df$Comsu_time))^2
sum((preds - mean(preds))^2) / sum((df$Comsu_time - mean(df$Comsu_time))^2)
inTrain <- createFolds(df, k=9,list = FALSE)
inTrain
inTrain <- createFolds(df, k=10)
inTrain
inTrain <- createFolds(df, k=10, list = FALSE)
inTrain
inTrain <- createFolds(df, k=2, list = FALSE)
inTrain
inTrain <- createFolds(df, k=1, list = FALSE)
inTrain
length(df)
dim(df)
inTrain = createDataPartition(df$Area, p=.8, list = FALSE)
trainX <- df[inTrain, ]
testX <- df[-inTrain, ]
modFit <- train(Comsu_time ~ Yield + Type + Area , method = 'glm', data=trainX)
preds = predict(modFit, testX)
cbind(testX$Comsu_time, preds)
conMatr <- confusionMatrix(testX$Comsu_time, pred)
conMatr <- confusionMatrix(testX$Comsu_time, preds)
sum((preds - testX$Comsu_time)^2)
mean((preds - testX$Comsu_time)^2)
modFit
predict(modFit, newdata = data.frame(Yield = 6000000, Type = 101PE, Area = '武汉'))
predict(modFit, newdata = data.frame(Yield = 6000000, Type = '101PE', Area = '武汉'))
df[Type]
df['Type']
sum(df[Type])
sum(df['Type'])
table(df['Type'])
q()
library(caret)
df = read.csv("/Users/Stamn/Data_Science/Python_work_dir/input/DT_Aug.csv", header=TRUE)
df = read.csv("/Users/Stamn/Data_Science/Python_work_dir/input/DT_Aug.csv", header=TRUE)
head(df)
table(df$Machine)
inTrain = createDataPartition(df$Machine, p=.8, list = FALSE)
testX = df[inTrain,]
trainX = df[inTrain,]
testX = df[-inTrain,]
library(car)
vif(df)
controlGLM <- trainControl(method='cv', number=3)
modFit = train(Coms_time ~ Yield + Machine + RL + Type + Area, method = 'glm', trainControl = controlGLM)
controlGLM <- trainControl(method='cv', number=3)
modFit = train(Coms_time ~ Yield + Machine + RL + Type + Area,
method = 'glm', data = trainX, trainControl = controlGLM)
controlGLM <- trainControl(method='cv', number=3)
modFit = train(Coms_time ~ Yield + Machine + RL + Type + Area,
method = 'glm', data = trainX, trainControl = controlGLM)
modFit = train(Coms_time ~ Yield + Machine + RL + Type + Area, method = 'glm', data = trainX, trainControl = controlGLM)
modFit = train(Coms_time ~ Yield + Machine + RL + Type + Area, method = 'glm', data = trainX)
modFit$finalModel
vif(modFit$finalModel)
modFit
modFit = train(Coms_time ~ Yield + Machine + RL + Type + Area, method = 'glm', data = trainX, preProcess='pca')
modFit
vif(modFit)
preds = predict(modFit, testX)
cbind(testX$Coms_time, preds)
modFit = train(Coms_time ~ Yield + Machine + RL + Type + Area, method = 'lda', data = trainX, preProcess='pca')
modFit = train(Coms_time ~ Yield + Machine + RL + Type + Area, method = 'lda', data = trainX)
modFit = train(Coms_time ~ Yield + Machine + RL + Type + Area, method = 'glm', data = trainX, preProcess='pca')
modFit = train(Coms_time ~ Yield + RL + Type + Area, method = 'glm', data = trainX, preProcess='pca')
modFit
modFit = train(Coms_time ~ Yield + Machine + RL + Type + Area, method = 'glm', data = trainX, preProcess='pca')
modFit2 = train(Coms_time ~ Yield + Machine + Type + Area, method = 'glm', data = trainX, preProcess='pca')
shapiro.test(modFit2$finalModel$residuals)
anova(modFit, modFit2)
anova(modFit$finalModel, modFit2$finalModel)
modFit2
modFit
anova(modFit$finalModel)
modFit2 = train(Coms_time ~ Yield + Machine + Type + Area, method = 'glm', data = trainX)
modFit2 = train(Coms_time ~ Yield + Machine + Type + RL + Area, method = 'glm', data = trainX)
anova(modFit2$finalModel)
testX[88,]
testX[1,]
testX[2,]
testX[3,]
testX[28,]
testX[28,]
testX[88,]
testX[28,]
testX[3,]
cbind(testX$Coms_time, preds)
testX[28,]
modFit
newdata = read.csv("/Users/Stamn/Data_Science/Python_work_dir/input/stand_data.csv", header=TRUE)
newdata
predict(modFit, newdata)
preds = predict(modFit, newdata)
cbind(newdata, preds)
q()
library(caret)
library(dplyr)
df = read.csv("/Users/Stamn/Data_Science/Python_work_dir/input/DT_Aug.csv", header=TRUE)
modFit = train(Coms_time ~ Yield + Machine + RL + Type + Area,
method = 'glm', data = df)
modFit
newdata = read.csv("/Users/Stamn/Data_Science/Python_work_dir/input/stand_data.csv", header=TRUE)
preds = predict(modFit, newdata)
standard = as.data.frame(cbind(newdata, round(preds*1.3, 2)))
standard = rename(standard, DT_time = `round(preds * 1.3, 2)`)
standard
modFit = train(Coms_time ~ Yield + Machine + RL + Type + Area,
method = 'gbm', data = df, preProcess='BoxCox')
modFit
modFit = train(Coms_time ~ Yield + Machine + RL + Type + Area,
method = 'gbm', data = df, preProcess='BoxCox', verbose=FALSE)
modFit
modFit = train(Coms_time ~ Yield + Machine + RL + Type + Area,
method = 'gbm', data = df, preProcess='BoxCox', verbose=FALSE)
modFit
preds = predict(modFit, newdata)
standard = as.data.frame(cbind(newdata, round(preds*1.3, 2)))
standard = rename(standard, DT_time = `round(preds * 1.3, 2)`)
standard
library(dplyr)
standard = rename(standard, DT_time = `round(preds * 1.3, 2)`)
standard = rename(standard, DT_time = `round(preds * 1.3, 2)`)
modFit = train(Coms_time ~ Yield + Machine + RL + Type + Area,
method = 'rf', data = df, preProcess='BoxCox', verbose=FALSE)
modFit
preds = predict(modFit, newdata)
standard = as.data.frame(cbind(newdata, round(preds*1.3, 2)))
standard = rename(standard, DT_time = `round(preds * 1.3, 2)`)
standard
modFit = train(Coms_time ~ Yield + Machine + RL + Type + Area,
method = 'glm', data = df, preProcess='BoxCox')
modFit
modFit = train(Coms_time ~ Yield + Machine + RL + Type + Area,
method = 'lda', data = df, preProcess='BoxCox')
modFit = train(Coms_time ~ Yield + Machine + RL + Type + Area,
method = 'glm', data = df, preProcess='BoxCox')
modFit
preds = predict(modFit, newdata)
standard = as.data.frame(cbind(newdata, round(preds*1.3, 2)))
standard = rename(standard, DT_time = `round(preds * 1.3, 2)`)
standard
modFit
q()
setwd("/Users/Stamn/Data_Science/Python_work_dir/input")
load("DT_BoxCox_glm.rda")
modFit$finalModel
shapiro.test(modFit$finalModel$residuals)
library(car)
vif(modFit$finalModel)
letters
LETTERS
q()
